{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "446e03db-ec23-4f2f-97f7-c1adf5fb165c",
   "metadata": {},
   "source": [
    "# Evaluation Model Roberta vs. unsere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d7a54c6-6959-47f1-9be9-bc0272255aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import math\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "683f949a-e705-4f51-9cfe-c670a41add15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Dataset/label_annotation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a78cbe31-e5e4-4379-baa5-922cb457cb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['output'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e4f64ee-26f1-4cc6-b368-4ab9ee4384e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a9dccc82-d4f1-4981-b645-228c22a9642d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 1041/1041 [00:58<00:00, 17.66row/s]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing Rows\", unit=\"row\"):\n",
    "        output = classifier(row['tweet'])\n",
    "    \n",
    "        df.at[index, 'output'] = output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "20d1b32e-d8c9-4e80-86dd-1831ac4cdfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['id','tweet', 'output']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6783e319-ca35-4045-827a-832d78b99ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@realDonaldTrump Sen. Jeff Merkley released a document showing a transfer of nearly $10 million from FEMA to ICE and accuses the Trump administration of diverting funds from hurricane relief just as hurricane season was beginning.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "04e02361-2109-48c3-9643-0f92014b246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['output'] = data['output'].astype(str)\n",
    "data['output'] = data['output'].apply(ast.literal_eval)\n",
    "\n",
    "def transform_row(row):\n",
    "    return {item['label']: item['score'] for item in row}\n",
    "\n",
    "new_data = data['output'].apply(transform_row).apply(pd.Series)\n",
    "\n",
    "result = pd.concat([data, new_data], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "090d37f9-2727-41f0-87a7-6908287f047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2765e174-e5ab-48e0-90c5-1452289bd30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet', 'output', 'fear', 'neutral', 'approval', 'realization',\n",
       "       'nervousness', 'annoyance', 'optimism', 'disgust', 'excitement',\n",
       "       'sadness', 'disapproval', 'admiration', 'disappointment', 'surprise',\n",
       "       'anger', 'caring', 'joy', 'confusion', 'amusement', 'desire',\n",
       "       'embarrassment', 'relief', 'grief', 'love', 'pride', 'curiosity',\n",
       "       'gratitude', 'remorse'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebd8982-1f7c-4230-8152-01a4036052fb",
   "metadata": {},
   "source": [
    "### SEMO MAPPING FROM CATEGORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7c9079b4-f053-494a-bcc2-d55ebac56eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_arousal = {\n",
    "    'anger':'high',\n",
    "    'fear':'high',\n",
    "    'disgust':'high',\n",
    "    'annoyance':'medium',\n",
    "    'disapproval':'medium',\n",
    "    'disappointment':'medium',\n",
    "    'confusion':'medium',\n",
    "    'nervousness':'medium',\n",
    "    'remorse':'medium',\n",
    "    'sadness':'medium',\n",
    "    'disgust':'low',\n",
    "    'grief':'low',\n",
    "    'curiosity':'high',\n",
    "    'realization':'high',\n",
    "    'neutral':'low',\n",
    "    'gratitude':'low',\n",
    "    'relief':'low',\n",
    "    'caring':'low',\n",
    "    'approval':'medium',\n",
    "    'optimism':'medium',\n",
    "    'admiration':'medium',\n",
    "    'pride':'medium',\n",
    "    'amusement':'medium',\n",
    "    'joy':'high',\n",
    "    'love':'high',\n",
    "    'excitement':'high'\n",
    "}\n",
    "\n",
    "df_valence = {\n",
    "    'anger':'negative',\n",
    "    'fear':'negative',\n",
    "    'disgust':'negative',\n",
    "    'annoyance':'negative',\n",
    "    'disapproval':'negative',\n",
    "    'disappointment':'negative',\n",
    "    'confusion':'negative',\n",
    "    'nervousness':'negative',\n",
    "    'remorse':'negative',\n",
    "    'sadness':'negative',\n",
    "    'disgust':'negative',\n",
    "    'grief':'negative',\n",
    "    'curiosity':'neutral',\n",
    "    'realization':'neutral',\n",
    "    'neutral':'neutral',\n",
    "    'gratitude':'positive',\n",
    "    'relief':'positive',\n",
    "    'caring':'positive',\n",
    "    'approval':'positive',\n",
    "    'optimism':'positive',\n",
    "    'admiration':'positive',\n",
    "    'pride':'positive',\n",
    "    'amusement':'positive',\n",
    "    'joy':'positive',\n",
    "    'love':'positive',\n",
    "    'excitement':'positive'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fea4621d-0741-4fb9-8688-9ab2b121effd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet', 'output', 'fear', 'neutral', 'approval', 'realization',\n",
       "       'nervousness', 'annoyance', 'optimism', 'disgust', 'excitement',\n",
       "       'sadness', 'disapproval', 'admiration', 'disappointment', 'surprise',\n",
       "       'anger', 'caring', 'joy', 'confusion', 'amusement', 'desire',\n",
       "       'embarrassment', 'relief', 'grief', 'love', 'pride', 'curiosity',\n",
       "       'gratitude', 'remorse', 'result'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "537cc008-80b8-4626-9cc3-ea03d70f30a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@tl_trevaskis @Bpage5 @CheriJacobus Which is exactly what is happening. Because trump has labeled antifa a terrorist organization he can now get away with authorizing federal officer to act under that law. This is what I was afraid of.'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['tweet'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7bb5ec31-9b43-4f28-9eda-b838fa2991a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_columns = result.columns.drop(['id','tweet', 'output'])\n",
    "result_new = result\n",
    "max_values = result[emotion_columns].max(axis=1)\n",
    "max_columns = result[emotion_columns].eq(max_values, axis=0)\n",
    "result_new['result'] = max_columns.apply(lambda x: ', '.join(x.index[x]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8a53b36a-3ad3-4469-ab2f-bbf0f8cb9b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@tl_trevaskis @Bpage5 @CheriJacobus Which is exactly what is happening. Because trump has labeled antifa a terrorist organization he can now get away with authorizing federal officer to act under that law. This is what I was afraid of.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['tweet'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e2e593c7-1ec5-42b2-8b93-a97ec4d16d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = result[['id','tweet', 'output']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "411f066c-23f7-4ab8-a0a8-128b40e53135",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([test, result_new], axis=1).loc[:, ~result.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "49c96a24-f20d-4c04-bad2-be77786694ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['valence_extern'] = result['result'].map(df_valence)\n",
    "result['arousal_extern'] = result['result'].map(df_arousal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369b22b-aded-4d7d-8d03-3c9bff9c858f",
   "metadata": {},
   "source": [
    "### Andere Modelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6959dd92-6405-4393-9dbb-522f984f394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_Aurosal = AutoTokenizer.from_pretrained('Arousal_Final_Model/')\n",
    "tokenizer_Valence = AutoTokenizer.from_pretrained('Valence_Final_Model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "92f2bb89-fe37-4c3f-b54e-d9040b58f1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arousal = AutoModelForSequenceClassification.from_pretrained('Arousal_Final_Model/')\n",
    "model_valence = AutoModelForSequenceClassification.from_pretrained('Valence_Final_Model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "46914667-1c90-46d7-8b4f-3a56d2025e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_valence.eval()\n",
    "model_arousal.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0cfbc59a-eb05-4d34-b9bc-effc8f305ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, model,tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    \n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    \n",
    "    predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "    \n",
    "    return  predicted_class\n",
    "\n",
    "def evaluate(data):\n",
    "    total = len(data)\n",
    "    required_columns = [ 'valence_pred','arousal_pred']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            data[col] = None  \n",
    "    for index, row in tqdm(data.iterrows(), total=total, desc=\"Processing Rows\", unit=\"row\"):\n",
    "        predict_arousal = predict(row['tweet'],model_arousal, tokenizer_Aurosal)\n",
    "        predict_valence = predict(row['tweet'],model_valence, tokenizer_Valence)\n",
    "        \n",
    "        data.at[index, 'valence_pred'] = predict_arousal\n",
    "        data.at[index, 'arousal_pred'] = predict_valence\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ddfc81e5-c8f5-4f07-b74c-eeb72bc3812b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 1041/1041 [03:00<00:00,  5.76row/s]\n"
     ]
    }
   ],
   "source": [
    "result = evaluate(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1f41add9-c55a-40b2-98c5-fb1cd9629c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'tweet', 'output', 'fear', 'neutral', 'approval', 'realization',\n",
       "       'nervousness', 'annoyance', 'optimism', 'disgust', 'excitement',\n",
       "       'sadness', 'disapproval', 'admiration', 'disappointment', 'surprise',\n",
       "       'anger', 'caring', 'joy', 'confusion', 'amusement', 'desire',\n",
       "       'embarrassment', 'relief', 'grief', 'love', 'pride', 'curiosity',\n",
       "       'gratitude', 'remorse', 'result', 'valence_extern', 'arousal_extern',\n",
       "       'valence_pred', 'arousal_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "134539f5-7a08-468b-97f2-53a78511d04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotator_one = result[['id','valence_extern', 'arousal_extern']]\n",
    "df_annotator_two = result[['id','valence_pred','arousal_pred']]\n",
    "df_human_ground_trth = pd.read_csv(\"../Dataset/human_truth.csv\",delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c461d471-f2ab-4600-99d3-ee1ba0dcd2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotator_one = df_annotator_one.dropna(subset=['valence_extern','arousal_extern'])\n",
    "df_annotator_two = df_annotator_two.dropna(subset=['valence_pred','arousal_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ee13bf-845d-4de2-b311-89cbdb6763e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annotator_one['valence'] = df_annotator_one['valence_extern']\n",
    "df_annotator_one['arousal'] = df_annotator_one['arousal_extern']\n",
    "df_annotator_two['arousal'] = df_annotator_two['valence_pred'] \n",
    "df_annotator_two['valence'] = df_annotator_two['arousal_pred'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f894425-c4bb-44d1-85df-fe2c8829f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_valence_map = {0: 'positive', 1: 'neutral', 2: 'negative'}\n",
    "inverted_arousal_map = {0: 'high', 1: 'medium', 2: 'low'}\n",
    "\n",
    "df_annotator_two['arousal'] = df_annotator_two['arousal'].map(inverted_arousal_map)\n",
    "df_annotator_two['valence'] = df_annotator_two['valence'].map(inverted_valence_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af5d7be6-c9ad-4bbe-a7c1-b0d4952386a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df):\n",
    "\n",
    "    valence_map = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "    arousal_map = {'high': 0, 'medium': 1, 'low': 2}\n",
    "    \n",
    "    df['Valence'] = df['valence'].map(valence_map)\n",
    "    df['Arousal'] = df['arousal'].map(arousal_map)\n",
    "    df = df.dropna(subset=['Valence', 'Arousal'])\n",
    "\n",
    "    df['Valence'] = df['Valence'].astype(int)\n",
    "    df['Arousal'] = df['Arousal'].astype(int)\n",
    "\n",
    "    \n",
    "    df['Combined'] = df['Valence'].astype(str) + '_' + df['Arousal'].astype(str)\n",
    "    df = df.dropna(subset=['Valence', 'Arousal', 'Combined'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a541b3-bd9e-412f-a91a-3e3502869b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jackknife_kappa(y1, y2):\n",
    "    n = len(y1)\n",
    "    kappas = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        mask = np.ones(n, dtype=bool)\n",
    "        mask[i] = False\n",
    "        kappas[i] = cohen_kappa_score(y1[mask], y2[mask])\n",
    "    \n",
    "    kappa = cohen_kappa_score(y1, y2)\n",
    "    se = np.sqrt(((n-1)/n) * np.sum((kappas - np.mean(kappas))**2))\n",
    "    \n",
    "    return kappa, se\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d01e7ee7-6b9d-4fcb-8872-0a6af385f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_kappa(df_label_one, df_label_two):\n",
    "    df1_processed = preprocess_df(df_label_one)\n",
    "    df2_processed = preprocess_df(df_label_two)\n",
    "\n",
    "    common_index = df1_processed.index.intersection(df2_processed.index)\n",
    "    df1_processed = df1_processed.loc[common_index]\n",
    "    df2_processed = df2_processed.loc[common_index]\n",
    "\n",
    "    df1_processed['Combined'] = df1_processed['Combined'].astype(str)\n",
    "    df2_processed['Combined'] = df2_processed['Combined'].astype(str)\n",
    "\n",
    "    kappa_valence, se_valence = jackknife_kappa(df1_processed['Valence'].values, df2_processed['Valence'].values)\n",
    "    kappa_arousal, se_arousal = jackknife_kappa(df1_processed['Arousal'].values, df2_processed['Arousal'].values)\n",
    "    kappa_combined, se_combined = jackknife_kappa(df1_processed['Combined'].values, df2_processed['Combined'].values)\n",
    "\n",
    "    return (kappa_valence, se_valence), (kappa_arousal, se_arousal), (kappa_combined, se_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21f82e55-3749-45ba-9e72-240c0b2cc8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "(valence_extern, se_valence_extern), (arousal_extern, se_arousal_extern), (combined_extern, se_combined_extern) = calculate_kappa(df_annotator_one, df_human_ground_trth)\n",
    "(valence_own, se_valence_own), (arousal_own, se_arousal_own), (combined_own, se_combined_own) = calculate_kappa(df_annotator_two, df_human_ground_trth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d8ca6f0-0074-42b1-bdf2-1b1a3dc4df99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########Groudn_truth | Extern##########\n",
      "Cohen's Kappa for Valence: 0.0898\n",
      "Cohen's Kappa for Valence Fehler: 0.0128\n",
      "Cohen's Kappa for Arousal: 0.0063\n",
      "Cohen's Kappa for Arousal Fehler: 0.0152\n",
      "Cohen's Kappa for Combined: 0.0316\n",
      "Cohen's Kappa for Combined Fehler: 0.0095\n"
     ]
    }
   ],
   "source": [
    "print(10*'#'+'Groudn_truth | Extern'+ 10*'#')\n",
    "print(f\"Cohen's Kappa for Valence: {valence_extern:.4f}\")\n",
    "print(f\"Cohen's Kappa for Valence Fehler: {se_valence_extern:.4f}\")\n",
    "print(f\"Cohen's Kappa for Arousal: {arousal_extern:.4f}\")\n",
    "print(f\"Cohen's Kappa for Arousal Fehler: {se_arousal_extern:.4f}\")\n",
    "print(f\"Cohen's Kappa for Combined: {combined_extern:.4f}\")\n",
    "print(f\"Cohen's Kappa for Combined Fehler: {se_combined_extern:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e87de37a-4e45-4028-adb1-23034a167d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########Groudn_truth | Unser##########\n",
      "Cohen's Kappa for Valence: 0.5689\n",
      "Cohen's Kappa for Valence Fehler: 0.0268\n",
      "Cohen's Kappa for Arousal: 0.4998\n",
      "Cohen's Kappa for Arousal Fehler: 0.0218\n",
      "Cohen's Kappa for Combined: 0.4279\n",
      "Cohen's Kappa for Combined Fehler: 0.0192\n"
     ]
    }
   ],
   "source": [
    "print(10*'#'+'Groudn_truth | Unser'+ 10*'#')\n",
    "print(f\"Cohen's Kappa for Valence: {valence_own:.4f}\")\n",
    "print(f\"Cohen's Kappa for Valence Fehler: {se_valence_own:.4f}\")\n",
    "\n",
    "print(f\"Cohen's Kappa for Arousal: {arousal_own:.4f}\")\n",
    "print(f\"Cohen's Kappa for Arousal Fehler: {se_arousal_own:.4f}\")\n",
    "\n",
    "print(f\"Cohen's Kappa for Combined: {combined_own:.4f}\")\n",
    "print(f\"Cohen's Kappa for Combined Fehler: {se_combined_own:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "354c3d66-b92f-494a-bc61-21c164c9eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_z_score(kappa1, se1, kappa2, se2):\n",
    "    \"\"\"\n",
    "    Berechnet den Z-Wert für den Vergleich zweier Kappa-Werte und gibt den p-Wert als Logarithmus zurück.\n",
    "    \n",
    "    :param kappa1: Erster Kappa-Wert\n",
    "    :param se1: Standardfehler des ersten Kappa-Werts\n",
    "    :param kappa2: Zweiter Kappa-Wert\n",
    "    :param se2: Standardfehler des zweiten Kappa-Werts\n",
    "    :return: Z-Wert und logarithmierter p-Wert\n",
    "    \"\"\"\n",
    "    z = (kappa1 - kappa2) / math.sqrt(se1**2 + se2**2)\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z)))  # Zweiseitiger p-Wert\n",
    "    log_p_value = math.log10(p_value) if p_value > 0 else float('-inf')\n",
    "    return z, log_p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73b14cf8-4a97-41d1-b075-efc28f72642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_p_value(log_p_value):\n",
    "    \"\"\"\n",
    "    Formatiert den logarithmierten p-Wert in eine lesbare wissenschaftliche Notation.\n",
    "    \"\"\"\n",
    "    if log_p_value == float('-inf'):\n",
    "        return \"p < 1e-324\"  # Kleinster darstellbarer Wert in Python\n",
    "    elif log_p_value > -4:  # Für p-Werte größer als 0.0001\n",
    "        return f\"{10**log_p_value:.4f}\"\n",
    "    else:\n",
    "        return f\"{10**log_p_value:.2e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9de6cb7c-f30a-4967-811f-ef18c54a779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Wert: 18.5122\n",
      "p-Wert: p < 1e-324\n",
      "Der Unterschied zwischen den Kappa-Werten ist statistisch signifikant.\n"
     ]
    }
   ],
   "source": [
    "z_score, p_value = calculate_z_score(combined_own, se_combined_own, combined_extern, se_combined_extern)\n",
    "print(f\"Z-Wert: {z_score:.4f}\")\n",
    "print(f\"p-Wert: {format_p_value(p_value)}\")\n",
    "\n",
    "alpha = 0.05 \n",
    "if p_value < alpha:\n",
    "    print(\"Der Unterschied zwischen den Kappa-Werten ist statistisch signifikant.\")\n",
    "else:\n",
    "    print(\"Der Unterschied zwischen den Kappa-Werten ist nicht statistisch signifikant.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa9f5793-a9f6-4d9f-bd23-652703dba0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score_v, p_value_v = calculate_z_score( valence_own, se_valence_own,valence_extern, se_valence_extern)\n",
    "z_score_a, p_value_a = calculate_z_score(arousal_own, se_arousal_own, arousal_extern, se_arousal_extern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47daf40a-8a84-4055-acc3-03d7055c3e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Wert_Valence: 16.1408\n",
      "p-Wert_Arousal: p < 1e-324\n"
     ]
    }
   ],
   "source": [
    "print(f\"Z-Wert_Valence: {z_score_v:.4f}\")\n",
    "print(f\"p-Wert_Arousal: {format_p_value(p_value_v)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9ae34b73-6301-42ee-8f38-f96478753b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z-Wert_Valence: 18.5542\n",
      "p-Wert_Arousal: p < 1e-324\n"
     ]
    }
   ],
   "source": [
    "print(f\"Z-Wert_Valence: {z_score_a:.4f}\")\n",
    "print(f\"p-Wert_Arousal: {format_p_value(p_value_a)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
